{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name : Khairul Basar\n",
    "## Roll : 1811176143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Khairul_Bashar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Khairul_Bashar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                64        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10625 (41.50 KB)\n",
      "Trainable params: 10625 (41.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Khairul_Bashar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Khairul_Bashar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "29/29 [==============================] - 3s 25ms/step - loss: 0.0633 - val_loss: 0.0271\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0185\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 7.8701e-04 - val_loss: 9.0985e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 4.7479e-04 - val_loss: 9.7660e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.1157e-04 - val_loss: 4.8984e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.4747e-04 - val_loss: 3.3251e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.2665e-04 - val_loss: 3.7025e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.6121e-04 - val_loss: 2.2775e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0761e-04 - val_loss: 2.7774e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.3568e-04 - val_loss: 3.0477e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 8.8281e-05 - val_loss: 1.3691e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 7.2942e-05 - val_loss: 1.0265e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 6.7067e-05 - val_loss: 1.3340e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 4.9399e-05 - val_loss: 8.3260e-05\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 3.7991e-05 - val_loss: 1.1460e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 3.5180e-05 - val_loss: 8.1021e-05\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 3.2244e-05 - val_loss: 8.6682e-05\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 3.3124e-05 - val_loss: 6.4516e-05\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 2.5852e-05 - val_loss: 3.9795e-05\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 2.8926e-05 - val_loss: 7.7258e-05\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 4.0541e-05 - val_loss: 5.3435e-05\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 2.3838e-05 - val_loss: 3.5511e-05\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.6261e-05 - val_loss: 4.0579e-05\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.9948e-05 - val_loss: 2.4782e-05\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.7891e-05 - val_loss: 6.8649e-05\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 2.3860e-05 - val_loss: 3.2553e-05\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.4890e-05 - val_loss: 3.4749e-05\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.1273e-05 - val_loss: 2.8905e-05\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 8.9579e-06 - val_loss: 1.8503e-05\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 8.8120e-06 - val_loss: 1.6590e-05\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.3989e-05 - val_loss: 3.4728e-05\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.2318e-06 - val_loss: 1.8659e-05\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.3548e-05 - val_loss: 5.0206e-05\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.4715e-05 - val_loss: 1.4579e-05\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.0795e-05 - val_loss: 3.3405e-05\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 8.0980e-06 - val_loss: 8.7793e-06\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 1.2967e-05 - val_loss: 2.3955e-05\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 8.2182e-06 - val_loss: 8.1084e-06\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 9.0478e-06 - val_loss: 4.2255e-05\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 8.9235e-06 - val_loss: 7.8129e-06\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.8610e-06 - val_loss: 1.6209e-05\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.1457e-05 - val_loss: 2.6548e-05\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 7.8628e-06 - val_loss: 1.5732e-05\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 5.1158e-06 - val_loss: 1.3755e-05\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 5.7646e-06 - val_loss: 9.5994e-06\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 5.7293e-06 - val_loss: 5.3811e-06\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 5.1706e-06 - val_loss: 9.4166e-06\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 2.8806e-06 - val_loss: 4.1106e-06\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 6.8744e-06 - val_loss: 1.1026e-05\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.7405e-05 - val_loss: 4.8291e-05\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 2.0410e-05 - val_loss: 2.0847e-05\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 8.4558e-06 - val_loss: 6.1193e-06\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.2857e-06 - val_loss: 1.5128e-05\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 7.4054e-06 - val_loss: 1.1538e-05\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 5.4689e-06 - val_loss: 6.2733e-06\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 3.1661e-06 - val_loss: 1.3214e-05\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 5.8154e-06 - val_loss: 1.4101e-05\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 3.2276e-05 - val_loss: 8.0334e-05\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.0747e-04 - val_loss: 9.6715e-05\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 8.0403e-05 - val_loss: 5.3969e-05\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 2.7848e-05 - val_loss: 1.3991e-05\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 7.2113e-06 - val_loss: 1.1570e-05\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 7.7097e-06 - val_loss: 1.5720e-05\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 9.4545e-06 - val_loss: 5.9391e-06\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 2.8765e-06 - val_loss: 6.2172e-06\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.2951e-06 - val_loss: 6.6337e-06\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.4758e-06 - val_loss: 4.1293e-06\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.2212e-06 - val_loss: 5.9891e-06\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.5200e-06 - val_loss: 1.0818e-05\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 2.5322e-06 - val_loss: 2.7887e-06\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 3.3807e-06 - val_loss: 6.5617e-06\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 3.3286e-05 - val_loss: 8.4789e-06\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 6.6108e-06 - val_loss: 1.0976e-05\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 8.1927e-06 - val_loss: 1.2504e-05\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 9.2040e-06 - val_loss: 5.1061e-06\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 5.7515e-06 - val_loss: 1.1185e-05\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 3.1859e-06 - val_loss: 3.5520e-06\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 2.8184e-06 - val_loss: 8.3311e-06\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 4.3921e-06 - val_loss: 1.6142e-05\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 3.3784e-06 - val_loss: 9.0218e-06\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 6.3205e-06 - val_loss: 3.1822e-05\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 8.3462e-06 - val_loss: 5.4056e-06\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.8770e-06 - val_loss: 2.0256e-06\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.1107e-06 - val_loss: 1.7021e-05\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 4.8083e-06 - val_loss: 6.5738e-06\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.1482e-06 - val_loss: 3.2542e-05\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.6805e-05 - val_loss: 5.1714e-06\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.5577e-05 - val_loss: 9.5344e-06\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.8554e-06 - val_loss: 3.5800e-06\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.1507e-06 - val_loss: 1.5681e-06\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.8006e-06 - val_loss: 2.9178e-06\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 3.6496e-06 - val_loss: 4.2074e-06\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 9.8638e-06 - val_loss: 7.2514e-05\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.9264e-05 - val_loss: 2.3848e-06\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.6218e-05 - val_loss: 2.1781e-05\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val))\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Plot training and validation accuracy\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the polynomial function\n",
    "def polynomial(x):\n",
    "    return 5*x**3 - 8*x**2 - 7*x + 1\n",
    "\n",
    "# Generate training samples\n",
    "np.random.seed(0)\n",
    "X = np.random.uniform(-20, 20, 1000)\n",
    "y = polynomial(X)\n",
    "\n",
    "# Normalize data to range [-1, 1]\n",
    "X_normalized = 2 * (X - np.min(X)) / (np.max(X) - np.min(X)) - 1\n",
    "y_normalized = 2 * (y - np.min(y)) / (np.max(y) - np.min(y)) - 1\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y_normalized, test_size=0.1, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the DNN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(1,)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot predictions vs true values\n",
    "plt.scatter(X_test, y_test, color='blue', label='True values')\n",
    "plt.scatter(X_test, y_pred, color='red', label='Predictions')\n",
    "plt.title('True values vs Predictions')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
